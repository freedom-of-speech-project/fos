install.packages(igraph)
install.packages(igraphdata)
install.packages(igraphdata-package)
install.packages(igraphdata-package)
install.packages(igraphdata-package)
install.packages(igraphdata-package)
install.packages("igraph")
install.packages("igraphdata")
library(readr)
bookshelf <- read_csv("~/Desktop/summer17/bookshelf.csv")
View(bookshelf)
source('~/Desktop/School Folders/Fall16/Honors/Invisible_Man_TM_annotated.R')
setwd("~/Users/evasibinga/fos/data_and_processing")
url = "https://raw.githubusercontent.com/freedom-of-speech-project/fos-data/main/litetmdataset.csv?token=ALBDZW36M2ARO6OK52QS4JTAOMXNK"
text.csv <- read_csv(url, what="character", sep="\n")
text.csv <- read.csv(url, what="character", sep="\n")
library(readxl)
text.csv <- read_csv(url, what="character", sep="\n")
library(readcsv)
text.csv <- read.csv(url, what="character", sep="\n")
)
text.csv <- read.csv(url)
text.csv <- read.csv(url, sep=",")
url <- "https://raw.githubusercontent.com/freedom-of-speech-project/fos-data/main/litetmdataset.csv?token=ALBDZW36M2ARO6OK52QS4JTAOMXNK"
text.csv <- read.csv(url, sep=",")
setwd("~/Users/evasibinga/fos/data_and_processing")
setwd("~/fos")
#url <- "https://raw.githubusercontent.com/freedom-of-speech-project/fos-data/main/litetmdataset.csv?token=ALBDZW36M2ARO6OK52QS4JTAOMXNK"
path <- "data_and_processing/tm-test.rtf"
text.csv <- read.csv(path, sep=",")
head(text.csv)
text.csv
text.csv[1:10]
head(text.csv)
#url <- "https://raw.githubusercontent.com/freedom-of-speech-project/fos-data/main/litetmdataset.csv?token=ALBDZW36M2ARO6OK52QS4JTAOMXNK"
path <- "data_and_processing/tm-test.txt"
text.csv <- read.csv(path, sep=",")
#url <- "https://raw.githubusercontent.com/freedom-of-speech-project/fos-data/main/litetmdataset.csv?token=ALBDZW36M2ARO6OK52QS4JTAOMXNK"
path <- "data_and_processing/tm-test.txt"
text.csv <- read.csv(path, sep=",")
head(text.csv)
colnames(text.csv, do.NULL = TRUE, prefix = "col")
text.csv$cleansyl
chapters <- text.csv$cleansyl
#chapters <- strings.v
chapters <- gsub("'", "", chapters)  # remove apostrophes
chapters <- gsub("[[:punct:]]", " ", chapters)  # replace punctuation with space
chapters <- gsub("[[:cntrl:]]", " ", chapters)  # replace control characters with space
chapters <- gsub("^[[:space:]]+", "", chapters) # remove whitespace at beginning of chapters
chapters <- gsub("[[:space:]]+$", "", chapters) # remove whitespace at end of chapters
chapters <- gsub('[[:digit:]]+', '', chapters)  # remove number digits
chapters <- tolower(chapters)                   # force to lowercase
chapters <- iconv(strings.v,to='UTF-8-MAC', sub='byte')  # make text formatting readable by Macs
chapters
chapter.list <- strsplit(chapters, "[[:space:]]+") # recognize each word as a single token, and output all as a list
# compute the table of terms-- the number of times each word is used in the novel
term.table <- table(unlist(chapter.list))
term.table <- sort(term.table, decreasing = TRUE)
print(dim(term.table))
# remove terms that are stop words or occur fewer than 5 times (standard practice for topic modeling)
stopWordFile = "stopWordFile.txt"
stop_words = scan(stopWordFile, what = "character", sep = "\n")
stop_words = scan(stopWordFile, what = "character", sep = "\n")
# remove terms that are stop words or occur fewer than 5 times (standard practice for topic modeling)
stopWordFile = "data_and_processing/stopWordFile.txt"
stop_words = scan(stopWordFile, what = "character", sep = "\n")
del <- names(term.table) %in% stop_words | term.table < 5 # this number can also change
term.table <- term.table[!del]
term.table <- term.table[which(names(term.table) != "")]
vocab <- names(term.table)
# put the chapters into the format required by the lda topic modeling package:
get.terms <- function(x) {
index <- match(x, vocab)
index <- index[!is.na(index)]
rbind(as.integer(index - 1), as.integer(rep(1, length(index))))
}
all.chapters <- lapply(chapter.list, get.terms)
# define variables necessary for lda topic modeling
D <- length(all.chapters)
W <- length(vocab)
chap.length <- sapply(all.chapters, function(x) sum(x[2, ]))
N <- sum(chap.length)
term.frequency <- as.integer(term.table)
# MCMC and model tuning parameters:
K <- 20 # number of topics -- this one has the greatest effect on the results
G <- 5000 # number of iterations of sampling over the corpus
alpha <- 0.2 # scalar value of Dirichlet hyperparameter for topic proportions
eta <- 0.2 # scalar value of Dirichlet hyperparameter for topic multinomials
# Fit the model: (infer topics across corpus using the parameters above)
# documentation for lda package:   https://cran.r-project.org/web/packages/lda/lda.pdf
install.packages("lda")
library(lda)
set.seed(357) # random number generator, but allows results to be reproduced
# if correctly understood, randomly generated results, like the topics, can be replicated on a corpus
t1 <- Sys.time()
# run the topic model!
fit <- lda.collapsed.gibbs.sampler(documents = all.chapters, K = K, vocab = vocab,
num.iterations = G, alpha = alpha,
eta = eta, initial = NULL, burnin = 1,
compute.log.likelihood = TRUE)
t2 <- Sys.time()
t2 - t1  # 20 topics took about 4 minutes on my laptop
# make a "top.words" spreadsheet that contains the top 10 words in each of the 20 topics
top.words <- top.topic.words(fit$topics,10, by.score=TRUE)
write.csv(top.words, "IMTopWords_20_by_10.csv", row.names=FALSE)
# determine propotional relationships between topics-- i.e. how important is each topic within a chapter? or compared to the other topics?
topic.proportions <- t(fit$document_sums) / colSums(fit$document_sums)
# put column names on so that you know which topic is referred to
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")
# show each chapter's representation of topics
write.csv(topic.proportions.df, "tm-test1_TopicProportions.csv")
# reshape the data from long format to wide format
library(reshape2)
topic.proportions.df <- cbind(data.frame(topic.proportions),
chapter=factor(1:length(all.chapters), labels = "chapter"))
topic.proportions.melt.df <- melt(topic.proportions.df)
# show each chapter's representation of topics
write.csv(topic.proportions.df, "tm-test1_TopicProportions.csv")
library(ggplot2)
install.packages("RColorBrewer")
library(RColorBrewer)            #install necessary packages for making graph and applying custom colors for better visualizations
colorCount <- 12 #length(unique(IM_TM_19$chapter))
getpalette <- colorRampPalette(brewer.pal(8, "Accent"))   # The normal color palette in ggplot will only use 11 colors, so I had to make my own palette with 19 colors (topic modeling for 20 topics, minus 1 extraneous )
ggplot(data=topic.proportions.df, aes(x=chapter, y=value, group=variable, fill=variable)) +   # plot a graph using IM_TM_19 data, graphed by chapter on the x axis ("chapter") and topic model values on the y axis ("value"), with color fill applied based upon the topic identity ("variable")
geom_bar(stat="identity") +    # make the plot a bar graph
scale_x_discrete("chapter", labels=c("chapter000"="Pro.", "chapter001"="1", "chapter002"="2", "chapter003"="3", "chapter004"="4", "chapter005"="5", "chapter006"="6", "chapter007"="7", "chapter008"="8", "chapter009"="9", "chapter010"="10", "chapter011"="11", "chapter012"="12", "chapter013"="13", "chapter014"="14", "chapter015"="15", "chapter016"="16", "chapter017"="17","chapter018"= "18", "chapter019"="19", "chapter020"="20", "chapter021"="21", "chapter022"="22", "chapter023"="23", "chapter024"="24", "chapter025"="25", "chapter026"="Ep.")) +      # change x axis labels to be more readable
scale_fill_manual(values=getpalette(colorCount))       # apply custom color palette to improve visualization
head(topic.proportions.df)
# Dependencies
require(tidyverse)
# Dependencies
library(tidyverse)
# Dependencies
install.packages(tidyverse)
install.packages(httr)
install.packages(rlist)
install.packages(jsonlite)
# Dependencies
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("httr")
install.packages("rlist")
install.packages("jsonlite")
library(tidyverse)
library(httr)
library(rlist)
library(jsonlite)
install.packages("tidyverse")
